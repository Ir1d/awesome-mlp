# awesome-mlp

- [CycleMLP: A MLP-like Architecture for Dense Prediction](https://arxiv.org/abs/2107.10224)
- [AS-MLP: An Axial Shifted MLP Architecture for Vision](https://arxiv.org/abs/2107.08391)
- [Global Filter Networks for Image Classification](https://arxiv.org/abs/2107.00645)
- [Rethinking Token-Mixing MLP for MLP-based Vision Backbone](https://arxiv.org/abs/2106.14882)
- [Vision Permutator: A Permutable MLP-Like Architecture for Visual Recognition](https://arxiv.org/abs/2106.12368)
- [S^2-MLP: Spatial-Shift MLP Architecture for Vision](https://arxiv.org/abs/2106.07477)
- [Graph-MLP: Node Classification without Message Passing in Graph](https://arxiv.org/abs/2106.04051)
- [When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations](https://arxiv.org/abs/2106.01548)
- [Container: Context Aggregation Network](https://arxiv.org/abs/2106.01401)
- [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)
- [Can Attention Enable MLPs To Catch Up With CNNs](https://arxiv.org/abs/2105.15078)
- [Transformer-Based Deep Image Matching for Generalizable Person Re-identification](https://arxiv.org/abs/2105.14432)
- [Less is More: Pay Less Attention in Vision Transformers](https://arxiv.org/abs/2105.14217)
- [MixerGAN: An MLP-Based Architecture for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2105.14110)
- [A remark on a paper of Krotov and Hopfield](https://arxiv.org/abs/2105.15034)
- [Pay Attention to MLPs](https://arxiv.org/abs/2105.08050)
- [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824)
- [ResMLP: Feedforward networks for image classification with data-efficient training](https://arxiv.org/abs/2105.03404)
- [Are Pre-trained Convolutions Better than Pre-trained Transformers?](https://arxiv.org/abs/2105.03322)
- [Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet](https://arxiv.org/abs/2105.02723)
- [Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks](https://arxiv.org/abs/2105.02358)
- [RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition](https://arxiv.org/abs/2105.01883)
- [MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/abs/2105.01601)
- [Synthesizer: Rethinking Self-Attention in Transformer Models](https://arxiv.org/abs/2005.00743)


## related repo

- https://github.com/dk-liang/Awesome-Visual-Transformer
- https://github.com/DirtyHarryLYL/Transformer-in-Vision
